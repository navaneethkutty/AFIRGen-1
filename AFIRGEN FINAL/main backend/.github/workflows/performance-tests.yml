# Performance Testing CI/CD Workflow
#
# This workflow runs performance benchmarks on every push to main and pull requests.
# It compares results against baseline metrics and fails if SLA thresholds are exceeded.
#
# Requirements: 9.6, 9.7

name: Performance Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      save_baseline:
        description: 'Save results as new baseline'
        required: false
        default: 'false'

jobs:
  performance-tests:
    name: Run Performance Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: test_password
          MYSQL_DATABASE: afirgen_test
        ports:
          - 3306:3306
        options: >-
          --health-cmd "mysqladmin ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-benchmark locust
      
      - name: Download baseline metrics
        uses: actions/cache@v3
        with:
          path: performance_baseline.json
          key: performance-baseline-${{ github.ref_name }}
          restore-keys: |
            performance-baseline-main
            performance-baseline-
      
      - name: Run performance benchmarks
        env:
          REDIS_HOST: localhost
          REDIS_PORT: 6379
          MYSQL_HOST: localhost
          MYSQL_PORT: 3306
          MYSQL_USER: root
          MYSQL_PASSWORD: test_password
          MYSQL_DATABASE: afirgen_test
        run: |
          python scripts/generate_performance_report.py \
            --run-tests \
            --baseline performance_baseline.json \
            --output-dir performance_reports \
            --fail-on-regression
      
      - name: Upload performance reports
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: performance-reports
          path: performance_reports/
          retention-days: 30
      
      - name: Save baseline (on main branch)
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          python scripts/generate_performance_report.py \
            --save-baseline \
            --baseline performance_baseline.json \
            --output-dir performance_reports
      
      - name: Save baseline (manual trigger)
        if: github.event_name == 'workflow_dispatch' && github.event.inputs.save_baseline == 'true'
        run: |
          python scripts/generate_performance_report.py \
            --save-baseline \
            --baseline performance_baseline.json \
            --output-dir performance_reports
      
      - name: Update baseline cache
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        uses: actions/cache@v3
        with:
          path: performance_baseline.json
          key: performance-baseline-${{ github.ref_name }}-${{ github.sha }}
      
      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('performance_reports/performance_summary.txt', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Performance Test Results\n\n\`\`\`\n${summary}\n\`\`\``
            });
      
      - name: Check SLA compliance
        run: |
          # This step will fail if any performance tests exceeded SLA thresholds
          # The --fail-on-regression flag in the earlier step handles this
          echo "Performance tests completed. Check reports for details."

  load-tests:
    name: Run Load Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install locust
      
      - name: Run Locust load tests
        run: |
          # Create a simple locustfile for load testing
          cat > locustfile.py << 'EOF'
          from locust import HttpUser, task, between
          
          class AFIRGenUser(HttpUser):
              wait_time = between(1, 3)
              
              @task(3)
              def get_session_status(self):
                  self.client.get("/api/v1/session/test_session_123/status")
              
              @task(2)
              def get_fir_status(self):
                  self.client.get("/api/v1/fir/FIR_123")
              
              @task(1)
              def validate_step(self):
                  self.client.post("/api/v1/validate", json={
                      "session_id": "test_session_123",
                      "approved": True
                  })
          EOF
          
          # Run load test (headless mode)
          locust -f locustfile.py \
            --headless \
            --users 15 \
            --spawn-rate 5 \
            --run-time 5m \
            --host http://localhost:8000 \
            --html load_test_report.html \
            --csv load_test_results
      
      - name: Upload load test reports
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: load-test-reports
          path: |
            load_test_report.html
            load_test_results*.csv
          retention-days: 30
